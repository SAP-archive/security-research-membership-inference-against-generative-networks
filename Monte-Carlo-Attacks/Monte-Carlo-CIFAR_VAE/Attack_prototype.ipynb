{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\d065042\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "c:\\users\\d065042\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########\n",
      "6000\n",
      "54000\n",
      "###########\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import argparse\n",
    "import glob\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sample import *\n",
    "from cifar10_params import *\n",
    "from utils import *\n",
    "\n",
    "exp_nos = 1\n",
    "instance_no = np.random.randint(10000)\n",
    "experiment = 'CIFAR10_MC_ATTACK' + str(instance_no)\n",
    "\n",
    "dt = np.dtype([('instance_no', int),\n",
    "               ('exp_no', int),\n",
    "               ('method', int), # 1 = white box, 2 = euclidean_PCA, 3 = hog, 4 = euclidean_PCA category, 5 = hog category, 6 = ais\n",
    "               ('pca_n', int),\n",
    "               ('percentage_of_data', float),\n",
    "               ('percentile', float),\n",
    "               ('mc_euclidean_no_batches', int), # stuff\n",
    "               ('mc_hog_no_batches', int), # stuff\n",
    "               ('sigma_ais', float),\n",
    "               ('11_perc_mc_attack_log', float),\n",
    "               ('11_perc_mc_attack_eps', float),\n",
    "               ('11_perc_mc_attack_frac', float), \n",
    "               ('50_perc_mc_attack_log', float), \n",
    "               ('50_perc_mc_attack_eps', float),\n",
    "               ('50_perc_mc_attack_frac', float),\n",
    "               ('50_perc_white_box', float),\n",
    "               ('11_perc_white_box', float),\n",
    "               ('50_perc_ais', float),\n",
    "               ('50_perc_ais_acc_rate', float),\n",
    "               ('successfull_set_attack_1', float),\n",
    "               ('successfull_set_attack_2', float),\n",
    "               ('successfull_set_attack_3', float)\n",
    "              ])\n",
    "\n",
    "experiment_results = []\n",
    "\n",
    "def print_elapsed_time():\n",
    "    end_time = int(time.time())\n",
    "    d = divmod(end_time-start_time,86400)  # days\n",
    "    h = divmod(d[1],3600)  # hours\n",
    "    m = divmod(h[1],60)  # minutes\n",
    "    s = m[1]  # seconds\n",
    "\n",
    "    print('Elapsed Time: %d days, %d hours, %d minutes, %d seconds' % (d[0],h[0],m[0],s))\n",
    "\n",
    "trX, vaX = load_cifar10_with_validation(0.1, True)\n",
    "teX = vaX[44000:]\n",
    "vaX = vaX[:44000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results_matrices(distances_real_vs_sample,distances_real_vs_train, d_min=0.1):\n",
    "\n",
    "    results_sample = np.zeros((len(distances_real_vs_sample),4))\n",
    "    for i in range(len(results_sample)):\n",
    "        # indicate that dataset is a sample\n",
    "        results_sample[i][0] = 0\n",
    "        \n",
    "        integral_approx = 0\n",
    "        integral_approx_log = 0\n",
    "        integral_approx_eps = 0\n",
    "        for eps in distances_real_vs_sample[i]:\n",
    "            if eps < d_min:\n",
    "                integral_approx = integral_approx + d_min/eps\n",
    "                integral_approx_log = integral_approx_log + (-np.log(eps/d_min))\n",
    "                integral_approx_eps = integral_approx_eps + 1\n",
    "\n",
    "        integral_approx = integral_approx/len(distances_real_vs_sample[0])\n",
    "        integral_approx_log = integral_approx_log/len(distances_real_vs_sample[0])\n",
    "        integral_approx_eps = integral_approx_eps/len(distances_real_vs_sample[0])\n",
    "\n",
    "        results_sample[i][1] = integral_approx_log\n",
    "        results_sample[i][2] = integral_approx_eps\n",
    "        results_sample[i][3] = integral_approx\n",
    "\n",
    "    results_train = np.zeros((len(distances_real_vs_train),4))\n",
    "    for i in range(len(results_train)):\n",
    "        # indicate that dataset is a training data set\n",
    "        results_train[i][0] = 1\n",
    "        \n",
    "        integral_approx = 0\n",
    "        integral_approx_log = 0\n",
    "        integral_approx_eps = 0\n",
    "        for eps in distances_real_vs_train[i]:\n",
    "            if eps < d_min:\n",
    "                integral_approx = integral_approx + d_min/eps\n",
    "                integral_approx_log = integral_approx_log + (-np.log(eps/d_min))\n",
    "                integral_approx_eps = integral_approx_eps + 1\n",
    "\n",
    "        integral_approx = integral_approx/len(distances_real_vs_train[0])\n",
    "        integral_approx_log = integral_approx_log/len(distances_real_vs_train[0])\n",
    "        integral_approx_eps = integral_approx_eps/len(distances_real_vs_train[0])\n",
    "\n",
    "        results_train[i][1] = integral_approx_log\n",
    "        results_train[i][2] = integral_approx_eps\n",
    "        results_train[i][3] = integral_approx\n",
    "        \n",
    "    return results_sample,results_train\n",
    "\n",
    "def mc_attack_sample(results_sample, results_train):\n",
    "    results = np.concatenate((results_sample, results_train))\n",
    "    np.random.shuffle(results)\n",
    "    mc_attack_log = results[results[:,1].argsort()][:,0][-len(results_train):].mean()\n",
    "    np.random.shuffle(results)\n",
    "    mc_attack_eps = results[results[:,2].argsort()][:,0][-len(results_train):].mean()\n",
    "    np.random.shuffle(results)\n",
    "    mc_attack_frac = results[results[:,3].argsort()][:,0][-len(results_train):].mean()\n",
    "\n",
    "    successfull_set_attack_1 = results_train[:,1].sum() > results_sample[:,1].sum()\n",
    "    successfull_set_attack_2 = results_train[:,2].sum() > results_sample[:,2].sum()\n",
    "    successfull_set_attack_3 = results_train[:,3].sum() > results_sample[:,3].sum()\n",
    "\n",
    "    return mc_attack_log, mc_attack_eps, mc_attack_frac, successfull_set_attack_1, successfull_set_attack_2, successfull_set_attack_3\n",
    "\n",
    "def mc_attack(results_sample, results_train):\n",
    "\n",
    "    mc_attack_log, mc_attack_eps, mc_attack_frac, successfull_set_attack_1, successfull_set_attack_2, successfull_set_attack_3 = mc_attack_sample(results_sample, results_train)\n",
    "\n",
    "    print('50_perc_mc_attack_log: %.3f'%(mc_attack_log))\n",
    "    print('50_perc_mc_attack_eps: %.3f'%(mc_attack_eps))\n",
    "    print('50_perc_mc_attack_frac: %.3f'%(mc_attack_frac))\n",
    "    print('successfull_set_attack_1: %.3f'%(successfull_set_attack_1))\n",
    "    print('successfull_set_attack_2: %.3f'%(successfull_set_attack_2))\n",
    "    print('successfull_set_attack_3: %.3f'%(successfull_set_attack_3))\n",
    "\n",
    "    iterations = 1000\n",
    "    results_attacks = np.zeros((iterations, 3))\n",
    "\n",
    "    for i in range(len(results_attacks)):\n",
    "        np.random.shuffle(results_train)\n",
    "        res = mc_attack_sample(results_sample, results_train[0:10])\n",
    "        results_attacks[i][0] = res[0]\n",
    "        results_attacks[i][1] = res[1]\n",
    "        results_attacks[i][2] = res[2]\n",
    "\n",
    "    return mc_attack_log, mc_attack_eps, mc_attack_frac, results_attacks[:,0].mean(), results_attacks[:,1].mean(), results_attacks[:,2].mean(), successfull_set_attack_1, successfull_set_attack_2, successfull_set_attack_3\n",
    "\n",
    "def euclidean_PCA_mc_attack(n_components_pca, trX_inds, vaX_inds, exp_no, mc_euclidean_no_batches, mc_sample_size):\n",
    "    pca = PCA(n_components=n_components_pca)\n",
    "\n",
    "    pca.fit_transform(teX.reshape((len(teX),3072)))\n",
    "\n",
    "    euclidean_trX = np.reshape(trX, (len(trX),3072))\n",
    "    euclidean_trX = euclidean_trX[trX_inds]\n",
    "    euclidean_trX = pca.transform(euclidean_trX)\n",
    "\n",
    "    euclidean_vaX = np.reshape(vaX, (len(vaX),3072))\n",
    "    euclidean_vaX = euclidean_vaX[vaX_inds]\n",
    "    euclidean_vaX = pca.transform(euclidean_vaX)\n",
    "\n",
    "    distances_trX = np.zeros((len(euclidean_trX), mc_euclidean_no_batches*mc_sample_size))\n",
    "    distances_vaX = np.zeros((len(euclidean_vaX), mc_euclidean_no_batches*mc_sample_size))\n",
    "\n",
    "    for i in range(mc_euclidean_no_batches):\n",
    "\n",
    "        print('Working on %d/%d'%(i, mc_euclidean_no_batches))\n",
    "\n",
    "        euclidean_generated_samples = sample_flattened(mc_sample_size)\n",
    "\n",
    "        euclidean_generated_samples = np.reshape(euclidean_generated_samples, (len(euclidean_generated_samples),3072))\n",
    "        euclidean_generated_samples = pca.transform(euclidean_generated_samples)\n",
    "\n",
    "        distances_trX_partial = scipy.spatial.distance.cdist(euclidean_trX, euclidean_generated_samples, 'euclidean')\n",
    "        distances_vaX_partial = scipy.spatial.distance.cdist(euclidean_vaX, euclidean_generated_samples, 'euclidean')\n",
    "\n",
    "        # optimized, better than concatenate\n",
    "        distances_trX[:,i*mc_sample_size:(i+1)*mc_sample_size] = distances_trX_partial\n",
    "        distances_vaX[:,i*mc_sample_size:(i+1)*mc_sample_size] = distances_vaX_partial\n",
    "        \n",
    "        print_elapsed_time()\n",
    "        \n",
    "    print('Calculating Results Matrices for flexible d_min...')\n",
    "    distances = np.concatenate((distances_trX,distances_vaX))\n",
    "    d_min = np.median([distances[i].min() for i in range(len(distances))])\n",
    "    results_sample,results_train = calculate_results_matrices(distances_vaX, distances_trX,d_min)\n",
    "\n",
    "    # save data\n",
    "    new_row = np.zeros(1, dtype = dt)[0]\n",
    "    new_row['instance_no'] = instance_no\n",
    "    new_row['exp_no'] = exp_no\n",
    "    new_row['method'] = 2 # euclidean PCA\n",
    "    new_row['pca_n'] = n_components_pca\n",
    "    new_row['percentage_of_data'] = 0.1\n",
    "    new_row['percentile'] = -1\n",
    "    new_row['mc_euclidean_no_batches'] = mc_euclidean_no_batches\n",
    "\n",
    "    mc_attack_results = mc_attack(results_sample, results_train)\n",
    "    new_row['50_perc_mc_attack_log'] = mc_attack_results[0]\n",
    "    new_row['50_perc_mc_attack_eps'] = mc_attack_results[1]\n",
    "    new_row['50_perc_mc_attack_frac'] = mc_attack_results[2]\n",
    "    new_row['11_perc_mc_attack_log'] = mc_attack_results[3]\n",
    "    new_row['11_perc_mc_attack_eps'] = mc_attack_results[4]\n",
    "    new_row['11_perc_mc_attack_frac'] = mc_attack_results[5]\n",
    "    new_row['successfull_set_attack_1'] = mc_attack_results[6]\n",
    "    new_row['successfull_set_attack_2'] = mc_attack_results[7]\n",
    "    new_row['successfull_set_attack_3'] = mc_attack_results[8]\n",
    "    \n",
    "    experiment_results.append(new_row)\n",
    "    np.savetxt(experiment+'.csv', np.array(experiment_results, dtype = dt))\n",
    "    \n",
    "def calc_hist(image): \n",
    "    vMin = np.amin(image)\n",
    "    vMax = np.amax(image)\n",
    "\n",
    "    image = (image-vMin)/(vMax-vMin)*255\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, [16, 16, 16],[0, 256, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist,hist).flatten()\n",
    "    return hist\n",
    "\n",
    "def calc_batch_hist(images):\n",
    "    features = np.zeros((len(images),4096))\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        features[i,:] = calc_hist(images[i])\n",
    "        \n",
    "    return features\n",
    "\n",
    "def color_hist_attack(mc_no_batches, mc_sample_size, trX_inds, vaX_inds, exp_no):\n",
    "\n",
    "    feature_matrix_vaX = calc_batch_hist(vaX[vaX_inds])\n",
    "    feature_matrix_trX = calc_batch_hist(trX[trX_inds])\n",
    "\n",
    "    distances_trX = np.zeros((len(feature_matrix_trX), mc_no_batches*mc_sample_size))\n",
    "    distances_vaX = np.zeros((len(feature_matrix_vaX), mc_no_batches*mc_sample_size))\n",
    "\n",
    "    for i in range(mc_no_batches):\n",
    "\n",
    "        print('Working on %d/%d'%(i, mc_no_batches))\n",
    "\n",
    "        generated_samples = sample(mc_sample_size)\n",
    "\n",
    "        feature_matrix_generated = calc_batch_hist(generated_samples)\n",
    "\n",
    "        distances_trX_partial = scipy.spatial.distance.cdist(feature_matrix_trX, feature_matrix_generated, 'euclidean')\n",
    "        distances_vaX_partial = scipy.spatial.distance.cdist(feature_matrix_vaX, feature_matrix_generated, 'euclidean')\n",
    "\n",
    "        # optimized, better than concatenate\n",
    "        distances_trX[:,i*mc_sample_size:(i+1)*mc_sample_size] = distances_trX_partial\n",
    "        distances_vaX[:,i*mc_sample_size:(i+1)*mc_sample_size] = distances_vaX_partial\n",
    "\n",
    "        print_elapsed_time()\n",
    "\n",
    "    print('Calculating Results Matrices for flexible d_min...')\n",
    "    distances = np.concatenate((distances_trX,distances_vaX))\n",
    "    d_min = np.median([distances[i].min() for i in range(len(distances))])\n",
    "    results_sample,results_train = calculate_results_matrices(distances_vaX, distances_trX,d_min)\n",
    "\n",
    "    # save data\n",
    "    new_row = np.zeros(1, dtype = dt)[0]\n",
    "    new_row['instance_no'] = instance_no\n",
    "    new_row['exp_no'] = exp_no\n",
    "    new_row['method'] = 8\n",
    "    new_row['percentage_of_data'] = 0.1\n",
    "    new_row['percentile'] = -1\n",
    "    new_row['mc_euclidean_no_batches'] = mc_no_batches\n",
    "    mc_attack_results = mc_attack(results_sample, results_train)\n",
    "    new_row['50_perc_mc_attack_log'] = mc_attack_results[0]\n",
    "    new_row['50_perc_mc_attack_eps'] = mc_attack_results[1]\n",
    "    new_row['50_perc_mc_attack_frac'] = mc_attack_results[2]\n",
    "    new_row['11_perc_mc_attack_log'] = mc_attack_results[3]\n",
    "    new_row['11_perc_mc_attack_eps'] = mc_attack_results[4]\n",
    "    new_row['11_perc_mc_attack_frac'] = mc_attack_results[5]\n",
    "    new_row['successfull_set_attack_1'] = mc_attack_results[6]\n",
    "    new_row['successfull_set_attack_2'] = mc_attack_results[7]\n",
    "    new_row['successfull_set_attack_3'] = mc_attack_results[8]\n",
    "    \n",
    "    experiment_results.append(new_row)\n",
    "    np.savetxt(experiment+'.csv', np.array(experiment_results, dtype = dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 0/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 3 seconds\n",
      "Working on 1/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 5 seconds\n",
      "Working on 2/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 7 seconds\n",
      "Working on 3/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 10 seconds\n",
      "Working on 4/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 12 seconds\n",
      "Working on 5/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 15 seconds\n",
      "Working on 6/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 17 seconds\n",
      "Working on 7/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 20 seconds\n",
      "Working on 8/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 22 seconds\n",
      "Working on 9/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 24 seconds\n",
      "Calculating Results Matrices for flexible d_min...\n",
      "50_perc_mc_attack_log: 0.470\n",
      "50_perc_mc_attack_eps: 0.470\n",
      "50_perc_mc_attack_frac: 0.470\n",
      "successfull_set_attack_1: 0.000\n",
      "successfull_set_attack_2: 0.000\n",
      "successfull_set_attack_3: 0.000\n"
     ]
    }
   ],
   "source": [
    "start_time = int(time.time())\n",
    "\n",
    "for exp_no in range(exp_nos):\n",
    "\n",
    "    trX_inds = np.arange(len(trX))\n",
    "    np.random.shuffle(trX_inds)\n",
    "    trX_inds = trX_inds[0:100]\n",
    "\n",
    "    vaX_inds = np.arange(len(vaX))\n",
    "    np.random.shuffle(vaX_inds)\n",
    "    vaX_inds = vaX_inds[0:100]\n",
    "\n",
    "    euclidean_PCA_mc_attack(40, trX_inds, vaX_inds, exp_no, 300, 10000)\n",
    "    print(experiment+': Finished PCA Monte Carlo 120 in experiment %d of %d'%(exp_no+1, exp_nos))\n",
    "\n",
    "    # color_hist_attack\n",
    "    color_hist_attack(300, 10000, trX_inds, vaX_inds, exp_no)\n",
    "    print(experiment+': Finished Color Hist in experiment %d of %d'%(exp_no+1, exp_nos))\n",
    "    \n",
    "    print_elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
