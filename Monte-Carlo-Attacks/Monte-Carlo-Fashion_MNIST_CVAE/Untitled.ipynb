{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\d065042\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from ./models/mnist_gan.ckpt-299\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import mnist_data\n",
    "import os\n",
    "import vae\n",
    "import plot_utils\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog\n",
    "\n",
    "\"\"\" parameters \"\"\"\n",
    "\n",
    "# source activate tensorflow_p36 && pip install pillow && pip install scikit-image && pip install scikit-learn\n",
    "# source activate tensorflow_p36 && python run_main.py --dim_z 10 --num_epochs 300\n",
    "# source activate tensorflow_p36 && python mc_attack_cvae.py 299 5 && python mc_attack_cvae.py 299 5 && sudo shutdown -P now\n",
    "\n",
    "# combined:\n",
    "# source activate tensorflow_p36 && pip install pillow && pip install scikit-image && pip install scikit-learn && python run_main.py --dim_z 10 --num_epochs 300 && python mc_attack_cvae.py 299 5 && python mc_attack_cvae.py 299 5 && sudo shutdown -P now\n",
    "# source activate tensorflow_p36 && python mc_attack_cvae.py 299 5 && python mc_attack_cvae.py 299 5 && sudo shutdown -P now\n",
    "# source activate tensorflow_p36 && python mc_attack_cvae.py 299 5 && python mc_attack_cvae.py 299 5 && python mc_attack_cvae.py 299 5 && sudo shutdown -P now\n",
    "model_no = '299' # which model to attack\n",
    "exp_nos = 1 # how many different experiments ofr specific indexes\n",
    "\n",
    "instance_no = np.random.randint(10000)\n",
    "experiment = 'MC_ATTACK_CVAE' + str(instance_no)\n",
    "percentage = np.loadtxt('percentage.csv')\n",
    "\n",
    "dt = np.dtype([('instance_no', int),\n",
    "               ('exp_no', int),\n",
    "               ('method', int), # 1 = white box, 2 = euclidean_PCA, 3 = hog, 4 = euclidean_PCA category, 5 = hog category, 6 = ais\n",
    "               ('pca_n', int),\n",
    "               ('percentage_of_data', float),\n",
    "               ('percentile', float),\n",
    "               ('mc_euclidean_no_batches', int), # stuff\n",
    "               ('mc_hog_no_batches', int), # stuff\n",
    "               ('sigma_ais', float),\n",
    "               ('11_perc_mc_attack_log', float),\n",
    "               ('11_perc_mc_attack_eps', float),\n",
    "               ('11_perc_mc_attack_frac', float), \n",
    "               ('50_perc_mc_attack_log', float), \n",
    "               ('50_perc_mc_attack_eps', float),\n",
    "               ('50_perc_mc_attack_frac', float),\n",
    "               ('50_perc_white_box', float),\n",
    "               ('11_perc_white_box', float),\n",
    "               ('50_perc_ais', float),\n",
    "               ('50_perc_ais_acc_rate', float),\n",
    "              ])\n",
    "\n",
    "experiment_results = []\n",
    "\n",
    "IMAGE_SIZE_MNIST = 28\n",
    "n_hidden = 500\n",
    "dim_img = IMAGE_SIZE_MNIST**2  # number of pixels for a MNIST image\n",
    "dim_z = 10\n",
    "\n",
    "\"\"\" prepare MNIST data \"\"\"\n",
    "\n",
    "train_total_data, train_size, valid_total_data, validation_size, test_total_data, test_size, _, _ = mnist_data.prepare_MNIST_data(reuse=True)\n",
    "# compatibility with old attack\n",
    "vaY = np.where(valid_total_data[:,784:795] == 1)[1]\n",
    "trY = np.where(train_total_data[:,784:795] == 1)[1]\n",
    "teY = np.where(test_total_data[:,784:795] == 1)[1]\n",
    "vaX = valid_total_data[:,0:784]\n",
    "trX = train_total_data[:,0:784]\n",
    "teX = test_total_data[:,0:784]\n",
    "n_samples = train_size\n",
    "\n",
    "\"\"\" build graph \"\"\"\n",
    "\n",
    "# input placeholders\n",
    "# In denoising-autoencoder, x_hat == x + noise, otherwise x_hat == x\n",
    "x_hat = tf.placeholder(tf.float32, shape=[None, dim_img], name='input_img')\n",
    "x = tf.placeholder(tf.float32, shape=[None, dim_img], name='target_img')\n",
    "y = tf.placeholder(tf.float32, shape=[None, mnist_data.NUM_LABELS], name='target_labels')\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "# input for PMLR\n",
    "z_in = tf.placeholder(tf.float32, shape=[None, dim_z], name='latent_variable')\n",
    "fack_id_in = tf.placeholder(tf.float32, shape=[None, mnist_data.NUM_LABELS], name='latent_variable')\n",
    "\n",
    "# network architecture\n",
    "x_, z, loss, neg_marginal_likelihood, KL_divergence = vae.autoencoder(x_hat, x, y, dim_img, dim_z, n_hidden, keep_prob)\n",
    "\n",
    "decoded = vae.decoder(z_in, fack_id_in, dim_img, n_hidden)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver = tf.train.import_meta_graph('models/mnist_gan.ckpt-'+model_no+'.meta')\n",
    "saver.restore(sess, './models/mnist_gan.ckpt-'+model_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHot(X, n=10, negative_class=0.):\n",
    "    X = np.asarray(X).flatten()\n",
    "    if n is None:\n",
    "        n = np.max(X) + 1\n",
    "    Xoh = np.ones((len(X), n)) * negative_class\n",
    "    Xoh[np.arange(len(X)), X] = 1.\n",
    "    return Xoh\n",
    "\n",
    "# indexes 1,11,21,31,... are ones, 2,12,22 are twos etc.\n",
    "def generate_samples_for_digits(sample_size=100):\n",
    "    \n",
    "    Z_np_sample_buffer = np.random.randn(sample_size, dim_z)\n",
    "    \n",
    "    digits = np.zeros((sample_size,)).astype(int)\n",
    "    for i in range(len(digits)):\n",
    "        digits[i] = i%10\n",
    "    Y_np_sample = OneHot( digits)\n",
    "\n",
    "    generated_samples = sess.run(decoded, feed_dict={z_in: Z_np_sample_buffer, fack_id_in: Y_np_sample, keep_prob : 1})\n",
    "\n",
    "    if (np.any(np.isnan(generated_samples))) or (not np.all(np.isfinite(generated_samples))):\n",
    "        print('Problem')\n",
    "        print(generated_samples[0])\n",
    "        print(generated_samples[1])\n",
    "        generated_samples = generate_samples_for_digits(sample_size)\n",
    "\n",
    "    return generated_samples\n",
    "\n",
    "def print_elapsed_time():\n",
    "    end_time = int(time.time())\n",
    "    d = divmod(end_time-start_time,86400)  # days\n",
    "    h = divmod(d[1],3600)  # hours\n",
    "    m = divmod(h[1],60)  # minutes\n",
    "    s = m[1]  # seconds\n",
    "\n",
    "    print('Elapsed Time: %d days, %d hours, %d minutes, %d seconds' % (d[0],h[0],m[0],s))\n",
    "\n",
    "def calculate_results_matrices(distances_real_vs_sample,distances_real_vs_train, d_min=0.1):\n",
    "\n",
    "    results_sample = np.zeros((len(distances_real_vs_sample),4))\n",
    "    for i in range(len(results_sample)):\n",
    "        # indicate that dataset is a sample\n",
    "        results_sample[i][0] = 0\n",
    "        \n",
    "        integral_approx = 0\n",
    "        integral_approx_log = 0\n",
    "        integral_approx_eps = 0\n",
    "        for eps in distances_real_vs_sample[i]:\n",
    "            if eps < d_min:\n",
    "                integral_approx = integral_approx + d_min/eps\n",
    "                integral_approx_log = integral_approx_log + (-np.log(eps/d_min))\n",
    "                integral_approx_eps = integral_approx_eps + 1\n",
    "\n",
    "        integral_approx = integral_approx/len(distances_real_vs_sample[0])\n",
    "        integral_approx_log = integral_approx_log/len(distances_real_vs_sample[0])\n",
    "        integral_approx_eps = integral_approx_eps/len(distances_real_vs_sample[0])\n",
    "\n",
    "        results_sample[i][1] = integral_approx_log\n",
    "        results_sample[i][2] = integral_approx_eps\n",
    "        results_sample[i][3] = integral_approx\n",
    "\n",
    "    results_train = np.zeros((len(distances_real_vs_train),4))\n",
    "    for i in range(len(results_train)):\n",
    "        # indicate that dataset is a training data set\n",
    "        results_train[i][0] = 1\n",
    "        \n",
    "        integral_approx = 0\n",
    "        integral_approx_log = 0\n",
    "        integral_approx_eps = 0\n",
    "        for eps in distances_real_vs_train[i]:\n",
    "            if eps < d_min:\n",
    "                integral_approx = integral_approx + d_min/eps\n",
    "                integral_approx_log = integral_approx_log + (-np.log(eps/d_min))\n",
    "                integral_approx_eps = integral_approx_eps + 1\n",
    "\n",
    "        integral_approx = integral_approx/len(distances_real_vs_train[0])\n",
    "        integral_approx_log = integral_approx_log/len(distances_real_vs_train[0])\n",
    "        integral_approx_eps = integral_approx_eps/len(distances_real_vs_train[0])\n",
    "\n",
    "        results_train[i][1] = integral_approx_log\n",
    "        results_train[i][2] = integral_approx_eps\n",
    "        results_train[i][3] = integral_approx\n",
    "        \n",
    "    return results_sample,results_train\n",
    "\n",
    "def mc_attack_sample(results_sample, results_train):\n",
    "    results = np.concatenate((results_sample, results_train))\n",
    "    np.random.shuffle(results)\n",
    "    mc_attack_log = results[results[:,1].argsort()][:,0][-len(results_train):].mean()\n",
    "    np.random.shuffle(results)\n",
    "    mc_attack_eps = results[results[:,2].argsort()][:,0][-len(results_train):].mean()\n",
    "    np.random.shuffle(results)\n",
    "    mc_attack_frac = results[results[:,3].argsort()][:,0][-len(results_train):].mean()\n",
    "\n",
    "    successfull_set_attack_1 = results_train[:,1].sum() > results_sample[:,1].sum()\n",
    "    successfull_set_attack_2 = results_train[:,2].sum() > results_sample[:,2].sum()\n",
    "    successfull_set_attack_3 = results_train[:,3].sum() > results_sample[:,3].sum()\n",
    "\n",
    "    return mc_attack_log, mc_attack_eps, mc_attack_frac, successfull_set_attack_1, successfull_set_attack_2, successfull_set_attack_3\n",
    "\n",
    "def mc_attack(results_sample, results_train):\n",
    "\n",
    "    mc_attack_log, mc_attack_eps, mc_attack_frac, successfull_set_attack_1, successfull_set_attack_2, successfull_set_attack_3 = mc_attack_sample(results_sample, results_train)\n",
    "\n",
    "    print('50_perc_mc_attack_log: %.3f'%(mc_attack_log))\n",
    "    print('50_perc_mc_attack_eps: %.3f'%(mc_attack_eps))\n",
    "    print('50_perc_mc_attack_frac: %.3f'%(mc_attack_frac))\n",
    "    print('successfull_set_attack_1: %.3f'%(successfull_set_attack_1))\n",
    "    print('successfull_set_attack_2: %.3f'%(successfull_set_attack_2))\n",
    "    print('successfull_set_attack_3: %.3f'%(successfull_set_attack_3))\n",
    "\n",
    "    iterations = 1000\n",
    "    results_attacks = np.zeros((iterations, 3))\n",
    "\n",
    "    for i in range(len(results_attacks)):\n",
    "        np.random.shuffle(results_train)\n",
    "        res = mc_attack_sample(results_sample, results_train[0:10])\n",
    "        results_attacks[i][0] = res[0]\n",
    "        results_attacks[i][1] = res[1]\n",
    "        results_attacks[i][2] = res[2]\n",
    "\n",
    "    print('11_perc_mc_attack_log: %.3f'%(results_attacks[:,0].mean()))\n",
    "    print('11_perc_mc_attack_eps: %.3f'%(results_attacks[:,1].mean()))\n",
    "    print('11_perc_mc_attack_frac: %.3f'%(results_attacks[:,2].mean()))\n",
    "\n",
    "    return mc_attack_log, mc_attack_eps, mc_attack_frac, results_attacks[:,0].mean(), results_attacks[:,1].mean(), results_attacks[:,2].mean(), successfull_set_attack_1, successfull_set_attack_2, successfull_set_attack_3\n",
    "\n",
    "def euclidean_PCA_mc_attack_category(n_components_pca, trX_inds, vaX_inds, exp_no, mc_euclidean_no_batches, mc_sample_size, percentiles):\n",
    "    pca = PCA(n_components=n_components_pca)\n",
    "\n",
    "    pca.fit_transform(teX.reshape((len(teX),784)))\n",
    "\n",
    "    euclidean_trX = np.reshape(trX, (len(trX),784,))\n",
    "    euclidean_trX = euclidean_trX[trX_inds]\n",
    "    euclidean_trX = pca.transform(euclidean_trX)\n",
    "\n",
    "    euclidean_vaX = np.reshape(vaX, (len(vaX),784,))\n",
    "    euclidean_vaX = euclidean_vaX[vaX_inds]\n",
    "    euclidean_vaX = pca.transform(euclidean_vaX)\n",
    "\n",
    "    distances_trX = np.zeros((len(euclidean_trX), mc_euclidean_no_batches*mc_sample_size // 10))\n",
    "    distances_vaX = np.zeros((len(euclidean_vaX), mc_euclidean_no_batches*mc_sample_size // 10))\n",
    "\n",
    "    for i in range(mc_euclidean_no_batches):\n",
    "\n",
    "        print('Working on %d/%d'%(i, mc_euclidean_no_batches))\n",
    "\n",
    "        euclidean_generated_samples = generate_samples_for_digits(mc_sample_size)\n",
    "\n",
    "        euclidean_generated_samples = np.reshape(euclidean_generated_samples, (len(euclidean_generated_samples),784,))\n",
    "        euclidean_generated_samples = pca.transform(euclidean_generated_samples)\n",
    "        \n",
    "        for digit in range(10):\n",
    "            # indexes of 1's, 2's, 3's etc.\n",
    "            digit_indexes_train = np.where(trY[trX_inds] == digit)\n",
    "            digit_indexes_sample = [digit+10*i for i in range(mc_sample_size//10)]\n",
    "            # only compare to current digit\n",
    "            distances_trX[digit_indexes_train,i*mc_sample_size//10:(i+1)*mc_sample_size//10] = scipy.spatial.distance.cdist(euclidean_trX[digit_indexes_train], euclidean_generated_samples[digit_indexes_sample], 'euclidean')\n",
    "\n",
    "        for digit in range(10):\n",
    "            # indexes of 1's, 2's, 3's etc.\n",
    "            digit_indexes_va = np.where(vaY[vaX_inds] == digit)\n",
    "            digit_indexes_sample = [digit+10*i for i in range(mc_sample_size//10)]\n",
    "            # only compare to current digit\n",
    "            distances_vaX[digit_indexes_va,i*mc_sample_size//10:(i+1)*mc_sample_size//10] = scipy.spatial.distance.cdist(euclidean_vaX[digit_indexes_va], euclidean_generated_samples[digit_indexes_sample], 'euclidean')\n",
    "        \n",
    "        print_elapsed_time()\n",
    "\n",
    "    for percentile in percentiles:\n",
    "        print_elapsed_time()\n",
    "        print('Calculating Results Matrices for '+str(percentile)+' Percentile...')\n",
    "\n",
    "        d_min = np.percentile(np.concatenate((distances_trX,distances_vaX)),percentile)\n",
    "        results_sample,results_train = calculate_results_matrices(distances_vaX, distances_trX,d_min)\n",
    "\n",
    "        # save data\n",
    "        new_row = np.zeros(1, dtype = dt)[0]\n",
    "        new_row['instance_no'] = instance_no\n",
    "        new_row['exp_no'] = exp_no\n",
    "        new_row['method'] = 4 # euclidean PCA cat\n",
    "        new_row['pca_n'] = n_components_pca\n",
    "        new_row['percentage_of_data'] = percentage\n",
    "        new_row['percentile'] = percentile\n",
    "        new_row['mc_euclidean_no_batches'] = mc_euclidean_no_batches\n",
    "\n",
    "        mc_attack_results = mc_attack(results_sample, results_train)\n",
    "        new_row['50_perc_mc_attack_log'] = mc_attack_results[0]\n",
    "        new_row['50_perc_mc_attack_eps'] = mc_attack_results[1]\n",
    "        new_row['50_perc_mc_attack_frac'] = mc_attack_results[2]\n",
    "        new_row['11_perc_mc_attack_log'] = mc_attack_results[3]\n",
    "        new_row['11_perc_mc_attack_eps'] = mc_attack_results[4]\n",
    "        new_row['11_perc_mc_attack_frac'] = mc_attack_results[5]\n",
    "        \n",
    "        experiment_results.append(new_row)\n",
    "        np.savetxt(experiment+'.csv', np.array(experiment_results, dtype = dt))\n",
    "    \n",
    "    print('Calculating Results Matrices for flexible d_min...')\n",
    "    distances = np.concatenate((distances_trX,distances_vaX))\n",
    "    d_min = np.percentile([distances[i].min() for i in range(len(distances))], 50)\n",
    "    results_sample,results_train = calculate_results_matrices(distances_vaX, distances_trX,d_min)\n",
    "\n",
    "    # save data\n",
    "    new_row = np.zeros(1, dtype = dt)[0]\n",
    "    new_row['instance_no'] = instance_no\n",
    "    new_row['exp_no'] = exp_no\n",
    "    new_row['method'] = 4 # euclidean PCA cat\n",
    "    new_row['pca_n'] = n_components_pca\n",
    "    new_row['percentage_of_data'] = percentage\n",
    "    new_row['percentile'] = -1 # dynamic\n",
    "    new_row['mc_euclidean_no_batches'] = mc_euclidean_no_batches\n",
    "    mc_attack_results = mc_attack(results_sample, results_train)\n",
    "    new_row['50_perc_mc_attack_log'] = mc_attack_results[0]\n",
    "    new_row['50_perc_mc_attack_eps'] = mc_attack_results[1]\n",
    "    new_row['50_perc_mc_attack_frac'] = mc_attack_results[2]\n",
    "    new_row['11_perc_mc_attack_log'] = mc_attack_results[3]\n",
    "    new_row['11_perc_mc_attack_eps'] = mc_attack_results[4]\n",
    "    new_row['11_perc_mc_attack_frac'] = mc_attack_results[5]\n",
    "    \n",
    "    experiment_results.append(new_row)\n",
    "    np.savetxt(experiment+'.csv', np.array(experiment_results, dtype = dt))\n",
    "    \n",
    "    print('Calculating Results Matrices for flexible d_min...')\n",
    "    distances = np.concatenate((distances_trX,distances_vaX))\n",
    "    d_min = np.percentile([distances[i].min() for i in range(len(distances))], 10)\n",
    "    results_sample,results_train = calculate_results_matrices(distances_vaX, distances_trX,d_min)\n",
    "\n",
    "    # save data\n",
    "    new_row = np.zeros(1, dtype = dt)[0]\n",
    "    new_row['instance_no'] = instance_no\n",
    "    new_row['exp_no'] = exp_no\n",
    "    new_row['method'] = 4 # euclidean PCA cat\n",
    "    new_row['pca_n'] = n_components_pca\n",
    "    new_row['percentage_of_data'] = percentage\n",
    "    new_row['percentile'] = -1 # dynamic\n",
    "    new_row['mc_euclidean_no_batches'] = mc_euclidean_no_batches\n",
    "    mc_attack_results = mc_attack(results_sample, results_train)\n",
    "    new_row['50_perc_mc_attack_log'] = mc_attack_results[0]\n",
    "    new_row['50_perc_mc_attack_eps'] = mc_attack_results[1]\n",
    "    new_row['50_perc_mc_attack_frac'] = mc_attack_results[2]\n",
    "    new_row['11_perc_mc_attack_log'] = mc_attack_results[3]\n",
    "    new_row['11_perc_mc_attack_eps'] = mc_attack_results[4]\n",
    "    new_row['11_perc_mc_attack_frac'] = mc_attack_results[5]\n",
    "    \n",
    "    experiment_results.append(new_row)\n",
    "    np.savetxt(experiment+'.csv', np.array(experiment_results, dtype = dt))\n",
    "\n",
    "    return results_sample,results_train\n",
    "\n",
    "def generate_batch_hog_features(samples):\n",
    "    features_matrix = np.zeros((len(samples),81))\n",
    "\n",
    "    for i in range(len(samples)):\n",
    "        features_matrix[i] = hog(samples[i].reshape((28, 28)), orientations=9, pixels_per_cell=(9, 9), visualise=False) #, transform_sqrt=True, block_norm='L2-Hys')\n",
    "    \n",
    "    return features_matrix\n",
    "\n",
    "def hog_mc_attack_category(trX_inds, vaX_inds, exp_no, mc_hog_no_batches, mc_sample_size, percentiles):\n",
    "\n",
    "    feature_matrix_vaX = generate_batch_hog_features(vaX[vaX_inds])\n",
    "    feature_matrix_trX = generate_batch_hog_features(trX[trX_inds])\n",
    "\n",
    "    distances_trX = np.zeros((len(feature_matrix_trX), mc_hog_no_batches*mc_sample_size // 10))\n",
    "    distances_vaX = np.zeros((len(feature_matrix_vaX), mc_hog_no_batches*mc_sample_size // 10))\n",
    "\n",
    "    for i in range(mc_hog_no_batches):\n",
    "\n",
    "        print('Working on %d/%d'%(i, mc_hog_no_batches))\n",
    "\n",
    "        generated_samples = generate_samples_for_digits(mc_sample_size)\n",
    "\n",
    "        generated_samples = generated_samples - generated_samples.min()\n",
    "        generated_samples = generated_samples*255/generated_samples.max()\n",
    "\n",
    "        feature_matrix_generated = generate_batch_hog_features(generated_samples)\n",
    "\n",
    "        for digit in range(10):\n",
    "            # indexes of 1's, 2's, 3's etc.\n",
    "            digit_indexes_train = np.where(trY[trX_inds] == digit)\n",
    "            digit_indexes_sample = [digit+10*i for i in range(mc_sample_size//10)]\n",
    "            # only compare to current digit\n",
    "            distances_trX[digit_indexes_train,i*mc_sample_size//10:(i+1)*mc_sample_size//10] = scipy.spatial.distance.cdist(feature_matrix_trX[digit_indexes_train], feature_matrix_generated[digit_indexes_sample], 'euclidean')\n",
    "\n",
    "        for digit in range(10):\n",
    "            # indexes of 1's, 2's, 3's etc.\n",
    "            digit_indexes_va = np.where(vaY[vaX_inds] == digit)\n",
    "            digit_indexes_sample = [digit+10*i for i in range(mc_sample_size//10)]\n",
    "            # only compare to current digit\n",
    "            distances_vaX[digit_indexes_va,i*mc_sample_size//10:(i+1)*mc_sample_size//10] = scipy.spatial.distance.cdist(feature_matrix_vaX[digit_indexes_va], feature_matrix_generated[digit_indexes_sample], 'euclidean')\n",
    "\n",
    "        print_elapsed_time()\n",
    "\n",
    "    for percentile in percentiles:\n",
    "        print_elapsed_time()\n",
    "        print('Calculating Results Matrices for '+str(percentile)+' Percentile...')\n",
    "\n",
    "        d_min = np.percentile(np.concatenate((distances_trX,distances_vaX)),percentile)\n",
    "        results_sample,results_train = calculate_results_matrices(distances_vaX, distances_trX,d_min)\n",
    "\n",
    "        # save data\n",
    "        new_row = np.zeros(1, dtype = dt)[0]\n",
    "        new_row['instance_no'] = instance_no\n",
    "        new_row['exp_no'] = exp_no\n",
    "        new_row['method'] = 5 # hog cat\n",
    "        new_row['percentage_of_data'] = percentage\n",
    "        new_row['percentile'] = percentile\n",
    "        new_row['mc_hog_no_batches'] = mc_hog_no_batches\n",
    "\n",
    "        mc_attack_results = mc_attack(results_sample, results_train)\n",
    "        new_row['50_perc_mc_attack_log'] = mc_attack_results[0]\n",
    "        new_row['50_perc_mc_attack_eps'] = mc_attack_results[1]\n",
    "        new_row['50_perc_mc_attack_frac'] = mc_attack_results[2]\n",
    "        new_row['11_perc_mc_attack_log'] = mc_attack_results[3]\n",
    "        new_row['11_perc_mc_attack_eps'] = mc_attack_results[4]\n",
    "        new_row['11_perc_mc_attack_frac'] = mc_attack_results[5]\n",
    "        \n",
    "        experiment_results.append(new_row)\n",
    "        np.savetxt(experiment+'.csv', np.array(experiment_results, dtype = dt))\n",
    "\n",
    "    print('Calculating Results Matrices for flexible d_min...')\n",
    "    distances = np.concatenate((distances_trX,distances_vaX))\n",
    "    d_min = np.median([distances[i].min() for i in range(len(distances))])\n",
    "    results_sample,results_train = calculate_results_matrices(distances_vaX, distances_trX,d_min)\n",
    "\n",
    "    # save data\n",
    "    new_row = np.zeros(1, dtype = dt)[0]\n",
    "    new_row['instance_no'] = instance_no\n",
    "    new_row['exp_no'] = exp_no\n",
    "    new_row['method'] = 5 # hog cat\n",
    "    new_row['percentage_of_data'] = percentage\n",
    "    new_row['percentile'] = -1\n",
    "    new_row['mc_hog_no_batches'] = mc_hog_no_batches\n",
    "\n",
    "    mc_attack_results = mc_attack(results_sample, results_train)\n",
    "    new_row['50_perc_mc_attack_log'] = mc_attack_results[0]\n",
    "    new_row['50_perc_mc_attack_eps'] = mc_attack_results[1]\n",
    "    new_row['50_perc_mc_attack_frac'] = mc_attack_results[2]\n",
    "    new_row['11_perc_mc_attack_log'] = mc_attack_results[3]\n",
    "    new_row['11_perc_mc_attack_eps'] = mc_attack_results[4]\n",
    "    new_row['11_perc_mc_attack_frac'] = mc_attack_results[5]\n",
    "    \n",
    "    experiment_results.append(new_row)\n",
    "    np.savetxt(experiment+'.csv', np.array(experiment_results, dtype = dt))\n",
    "\n",
    "    return results_sample,results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 0/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 3 seconds\n",
      "Working on 1/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 5 seconds\n",
      "Working on 2/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 7 seconds\n",
      "Working on 3/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 9 seconds\n",
      "Working on 4/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 12 seconds\n",
      "Working on 5/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 14 seconds\n",
      "Working on 6/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 17 seconds\n",
      "Working on 7/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 19 seconds\n",
      "Working on 8/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 21 seconds\n",
      "Working on 9/10\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 23 seconds\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 23 seconds\n",
      "Calculating Results Matrices for 100 Percentile...\n",
      "50_perc_mc_attack_log: 0.540\n",
      "50_perc_mc_attack_eps: 0.540\n",
      "50_perc_mc_attack_frac: 0.530\n",
      "successfull_set_attack_1: 1.000\n",
      "successfull_set_attack_2: 0.000\n",
      "successfull_set_attack_3: 1.000\n",
      "11_perc_mc_attack_log: 0.112\n",
      "11_perc_mc_attack_eps: 0.087\n",
      "11_perc_mc_attack_frac: 0.111\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 45 seconds\n",
      "Calculating Results Matrices for 1 Percentile...\n",
      "50_perc_mc_attack_log: 0.570\n",
      "50_perc_mc_attack_eps: 0.560\n",
      "50_perc_mc_attack_frac: 0.560\n",
      "successfull_set_attack_1: 1.000\n",
      "successfull_set_attack_2: 1.000\n",
      "successfull_set_attack_3: 1.000\n",
      "11_perc_mc_attack_log: 0.107\n",
      "11_perc_mc_attack_eps: 0.114\n",
      "11_perc_mc_attack_frac: 0.114\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 47 seconds\n",
      "Calculating Results Matrices for 0.1 Percentile...\n",
      "50_perc_mc_attack_log: 0.600\n",
      "50_perc_mc_attack_eps: 0.620\n",
      "50_perc_mc_attack_frac: 0.580\n",
      "successfull_set_attack_1: 1.000\n",
      "successfull_set_attack_2: 1.000\n",
      "successfull_set_attack_3: 1.000\n",
      "11_perc_mc_attack_log: 0.100\n",
      "11_perc_mc_attack_eps: 0.112\n",
      "11_perc_mc_attack_frac: 0.112\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 49 seconds\n",
      "Calculating Results Matrices for 0.01 Percentile...\n",
      "50_perc_mc_attack_log: 0.540\n",
      "50_perc_mc_attack_eps: 0.570\n",
      "50_perc_mc_attack_frac: 0.570\n",
      "successfull_set_attack_1: 1.000\n",
      "successfull_set_attack_2: 1.000\n",
      "successfull_set_attack_3: 1.000\n",
      "11_perc_mc_attack_log: 0.137\n",
      "11_perc_mc_attack_eps: 0.122\n",
      "11_perc_mc_attack_frac: 0.120\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 51 seconds\n",
      "Calculating Results Matrices for 0.001 Percentile...\n",
      "50_perc_mc_attack_log: 0.550\n",
      "50_perc_mc_attack_eps: 0.580\n",
      "50_perc_mc_attack_frac: 0.460\n",
      "successfull_set_attack_1: 0.000\n",
      "successfull_set_attack_2: 0.000\n",
      "successfull_set_attack_3: 0.000\n",
      "11_perc_mc_attack_log: 0.147\n",
      "11_perc_mc_attack_eps: 0.149\n",
      "11_perc_mc_attack_frac: 0.145\n",
      "Calculating Results Matrices for flexible d_min...\n",
      "50_perc_mc_attack_log: 0.570\n",
      "50_perc_mc_attack_eps: 0.570\n",
      "50_perc_mc_attack_frac: 0.570\n",
      "successfull_set_attack_1: 1.000\n",
      "successfull_set_attack_2: 1.000\n",
      "successfull_set_attack_3: 1.000\n",
      "11_perc_mc_attack_log: 0.108\n",
      "11_perc_mc_attack_eps: 0.115\n",
      "11_perc_mc_attack_frac: 0.115\n",
      "Calculating Results Matrices for flexible d_min...\n",
      "50_perc_mc_attack_log: 0.450\n",
      "50_perc_mc_attack_eps: 0.460\n",
      "50_perc_mc_attack_frac: 0.500\n",
      "successfull_set_attack_1: 0.000\n",
      "successfull_set_attack_2: 1.000\n",
      "successfull_set_attack_3: 1.000\n",
      "11_perc_mc_attack_log: 0.148\n",
      "11_perc_mc_attack_eps: 0.147\n",
      "11_perc_mc_attack_frac: 0.145\n",
      "MC_ATTACK_CVAE7631: Finished CATEGORY PCA Monte Carlo in experiment 1 of 1\n",
      "Elapsed Time: 0 days, 0 hours, 0 minutes, 57 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = int(time.time())\n",
    "\n",
    "for exp_no in range(exp_nos):\n",
    "\n",
    "    trX_inds = np.arange(len(trX))\n",
    "    np.random.shuffle(trX_inds)\n",
    "    trX_inds = trX_inds[0:100]\n",
    "\n",
    "    vaX_inds = np.arange(len(trX))\n",
    "    np.random.shuffle(vaX_inds)\n",
    "    vaX_inds = vaX_inds[0:100]\n",
    "\n",
    "    # white box attack\n",
    "    #wb_attack(trX_inds, vaX_inds, exp_no)\n",
    "    #print(experiment+': Finished White Box in experiment %d of %d'%(exp_no+1, exp_nos))\n",
    "    \n",
    "    ## hog mc attack \n",
    "    ## 100 iterations each having 10000 instances for monte carlo simulation\n",
    "    ## higher amount of instances exceeds memory\n",
    "    # 100\n",
    "    #hog_mc_attack(trX_inds, vaX_inds, exp_no, 100, 10000, [1,0.1,0.01, 0.001, 0.001])\n",
    "    #print(experiment+': Finished HOG (Default) Monte Carlo in experiment %d of %d'%(exp_no+1, exp_nos))\n",
    "\n",
    "    ## euclidean pca mc attack\n",
    "    ## 3 mins\n",
    "    # 200\n",
    "    #euclidean_PCA_mc_attack(40, trX_inds, vaX_inds, exp_no, 200, 10000, [1,0.1,0.01,0.001])\n",
    "    #print(experiment+': Finished PCA Monte Carlo in experiment %d of %d'%(exp_no+1, exp_nos))\n",
    "\n",
    "    ## pca category\n",
    "    # 8:00 mins 500\n",
    "    # 500\n",
    "    ## 300 iterations each having 30000 instances for monte carlo simulation (1h together with below)\n",
    "    results_sample_pca,results_train_pca = euclidean_PCA_mc_attack_category(40, trX_inds, vaX_inds, exp_no, 10, 30000, [1,0.1, 0.01, 0.001])\n",
    "    print(experiment+': Finished CATEGORY PCA Monte Carlo in experiment %d of %d'%(exp_no+1, exp_nos))\n",
    "\n",
    "    # hog category (6s per Iteration, )\n",
    "    # 300\n",
    "    #results_sample_hog,results_train_hog = hog_mc_attack_category(trX_inds, vaX_inds, exp_no, 10, 30000, [1,0.1,0.01, 0.001])\n",
    "    #print(experiment+': Finished CATEGORY HOG (Default) Monte Carlo in experiment %d of %d'%(exp_no+1, exp_nos))\n",
    "    \n",
    "    #results_train_combined = results_train_pca + results_train_hog\n",
    "    #results_train_combined[:,0] = 1\n",
    "    #results_train_combined\n",
    "    #mc_attack(results_sample_pca + results_sample_hog, results_train_combined)\n",
    "    #print(experiment+': Finished Bagging Monte Carlo in experiment %d of %d'%(exp_no+1, exp_nos))\n",
    "    \n",
    "    print_elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
